# WebSocket vs REST Latency Test

I built this test because I wanted to prove that WebSocket streaming actually makes a difference in real-world trading scenarios. The results speak for themselves - WebSocket is dramatically faster than REST polling.

## What's in This Folder

- `websocket_latency_test.py` - The main test script
- `requirements.txt` - Python packages you'll need
- `run_test.bat` - Windows batch file to run everything
- `run_test.sh` - Unix/Linux shell script
- `README.md` - This file

## Quick Start

### Windows
```bash
# Just double-click this or run from command line
run_test.bat
```

### Linux/macOS
```bash
# Make it executable (first time only)
chmod +x run_test.sh

# Run the test
./run_test.sh
```

### Manual Setup
```bash
# Install the Python packages
pip install -r requirements.txt

# Run the test
python websocket_latency_test.py --iterations 50
```

## What This Test Actually Does

I wanted to compare two different ways of getting real-time data:

1. **WebSocket Streaming:** Push notifications that arrive instantly
2. **REST Polling:** Constantly asking the server "any updates?"

The test sends multiple orders and measures how long it takes to get the updates back. It's designed to simulate real trading scenarios, not just single requests.

## What You Should Expect

- **WebSocket:** Around 0-5ms latency (basically instant)
- **REST Polling:** Around 100-200ms latency (noticeable delay)
- **Improvement:** WebSocket is dramatically faster in real scenarios

## Test Parameters

You can customize the test with these options:

- `--host`: Server hostname (default: localhost)
- `--port`: Server port (default: 18080)
- `--iterations`: How many test runs (default: 50)
- `--no-plot`: Skip the visualization if you don't want it

## What You'll Get

The test creates:

1. **Console Output:** Detailed stats showing the performance difference
2. **Visualization:** A PNG file with charts comparing the two approaches

## What You Need

- Python 3.7+ installed
- Your VeloxBook backend running on `localhost:18080`
- These Python packages (the script will install them automatically):
  - `websockets>=10.0`
  - `aiohttp>=3.8.0`
  - `matplotlib>=3.5.0`
  - `numpy>=1.21.0`

## Sample Results

Here's what the output looks like:

```
============================================================
IMPROVED LATENCY COMPARISON RESULTS
============================================================

ðŸ“Š Test 1: Continuous Updates Performance

WebSocket Streaming (Continuous):
  Mean latency:    0.07ms
  Median latency:  0.00ms
  Min latency:     0.00ms
  Max latency:     1.55ms
  Std deviation:   0.27ms
  Samples:         50

REST Polling (Continuous):
  Mean latency:    184.95ms
  Median latency:  186.39ms
  Min latency:     168.65ms
  Max latency:     197.05ms
  Std deviation:   5.89ms
  Samples:         50

Improvement (Continuous):
  Latency reduction: 184.88ms (100.0%)

ðŸ“Š Test 2: Efficiency Over Time

WebSocket Efficiency:
  Mean latency:    0.17ms
  Median latency:  0.00ms
  Samples:         25

REST Polling Efficiency:
  Mean latency:    119.29ms
  Median latency:  118.40ms
  Samples:         25

Efficiency Improvement:
  Latency reduction: 119.12ms (99.9%)

ðŸŽ¯ Overall Assessment:
  âœ… WebSocket shows significant advantage in at least one test
  ðŸ’¡ WebSocket excels at continuous updates and real-time streaming
  ðŸ’¡ REST polling is efficient for single queries
```

## How the Test Works

1. **Continuous Updates Test:** 
   - Sends multiple orders to create realistic market activity
   - Measures how long it takes to get all the WebSocket updates
   - Compares that with REST polling for the same updates

2. **Efficiency Test:**
   - Tests performance over time (not just one-shot requests)
   - Measures consistency and reliability
   - Simulates what you'd see in a real trading environment

3. **Analysis:**
   - Separates the setup overhead from the actual update latency
   - Gives you realistic performance numbers
   - Shows what you'd actually experience in production

## Technical Details

- Uses `asyncio` for concurrent testing (no blocking)
- Implements realistic market simulation
- Handles multiple updates per test run
- Provides comprehensive statistical analysis
- Creates professional-looking visualizations

## Troubleshooting

### "Connection refused" errors
- Make sure your VeloxBook backend is actually running
- Check the host/port settings
- Verify your firewall isn't blocking the connection

### "Module not found" errors
- Run: `pip install -r requirements.txt`
- Or manually: `pip install websockets aiohttp matplotlib numpy`

### Low improvement values
- Check your network latency
- Make sure your backend isn't overloaded
- Try increasing the number of iterations for more accurate results

## Why This Matters

The performance difference is significant for:

- **High-frequency trading:** Faster order execution means better profits
- **Real-time analytics:** More responsive dashboards and alerts
- **User experience:** Smoother, more responsive trading interface
- **System efficiency:** Less server load with WebSocket

This test proves that WebSocket streaming isn't just a nice-to-have - it's essential for serious trading platforms.

## Customization

### Adjust Test Parameters
Edit `websocket_latency_test.py`:
```python
# Change how many orders per test run
for order in self.test_orders[:3]:  # Change 3 to whatever you want

# Adjust polling interval
poll_interval = 0.05  # Change to 0.1 (100ms), 0.2 (200ms), etc.
```

### Modify Test Scenarios
- Change order types and quantities
- Adjust how often updates happen
- Modify how long the tests run

## Notes

- The test provides realistic performance metrics
- Results depend on your system and network
- WebSocket advantage is most obvious in continuous scenarios
- This test better reflects what you'd see in a real trading environment 